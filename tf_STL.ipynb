{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training/test files in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd() + '/data/training_csv'))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd() + '/data/test_csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we are enabling eager execution for debugging!\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for handling datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load filenames and labels\n",
    "filenames = tf.constant(train_data.iloc[:, 0].tolist())\n",
    "labels = tf.constant(train_data.iloc[:, 1:].values)\n",
    "\n",
    "# Add to a dataset object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "# We can debug using eager execution\n",
    "for img, labels in dataset.batch(4).take(1):\n",
    "    print(img)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    print(filename)\n",
    "    image_string = tf.read_file(filename) \n",
    "    print(image_string)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3) # Channels needed because some test images are b/w\n",
    "    image_resized = tf.image.resize_images(image_decoded, [160, 160])\n",
    "    image_shape = tf.cast(tf.shape(image_decoded), tf.float32)\n",
    "#     label = tf.concat([label[:]], axis=0)\n",
    "    return {\"x\": image_resized}, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet is adapted from here: https://www.tensorflow.org/guide/datasets\n",
    "def input_fn(dataframe, is_eval=False):\n",
    "\n",
    "    # Load the list of files\n",
    "    filenames = tf.constant(dataframe.iloc[:, 0].tolist())\n",
    "\n",
    "    # Load the labels\n",
    "    labels = tf.constant(dataframe.iloc[:, 1:].values)\n",
    "\n",
    "    # Build the dataset with image processing on top of it\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    # Add shuffling and repeatition if training\n",
    "    if is_eval:\n",
    "        dataset = dataset.batch(64)\n",
    "    else:\n",
    "        dataset = dataset.repeat().shuffle(1000).batch(64)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the image & some labels\n",
    "import matplotlib.pyplot as plt\n",
    "for (imgs, labels) in input_fn(train_data, is_eval=True).take(1):\n",
    "    plt.imshow(imgs['x'][0] / 255)\n",
    "    print(labels[0])\n",
    "    print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard classical estimator (single-task only!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reimplement the feature extraction from the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(features):\n",
    "    # Input layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 160, 160, 3])\n",
    "\n",
    "    # First convolutive layer\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=16, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Second convolutive layer\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=48, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Third convolutive layer\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fourth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fifth convolutive layer\n",
    "    conv5 = tf.layers.conv2d(inputs=pool4, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Fourth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=128, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer\n",
    "    flat = tf.reshape(conv4, [-1, 20 * 20 * 128])\n",
    "    dense = tf.layers.dense(inputs=flat, units=100, activation=tf.nn.relu)\n",
    "  \n",
    "    return dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single task cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from here: https://www.tensorflow.org/tutorials/layers\n",
    "def single_task_cnn_model_fn(features, labels, mode):\n",
    "  \n",
    "    # Get features\n",
    "    dense = extract_features(features)\n",
    "  \n",
    "    # Make predictions\n",
    "    logits = tf.layers.dense(inputs=dense, units=11)\n",
    "\n",
    "    predicted_class = tf.argmax(logits, 1)\n",
    "    \n",
    "    outputs = {\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"probabilities\": tf.nn.softmax(logits),\n",
    "        \"logits\": logits\n",
    "    }\n",
    "\n",
    "    # We just want the predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=outputs)\n",
    "\n",
    "    # If not in mode.PREDICT, compute the loss \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels[:], logits=logits)\n",
    "\n",
    "    # Single optimization step\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # If not PREDICT or TRAIN, then we are evaluating the model\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels[:, 0], predictions=outputs[\"predicted_class\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_task_classifier = tf.estimator.Estimator(\n",
    "    model_fn=single_task_cnn_model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & evaluate & test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "single_task_classifier.train(input_fn=lambda: input_fn(train_data), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_task_classifier.evaluate(input_fn=lambda: input_fn(test_data, is_eval=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = list(single_task_classifier.predict(lambda: input_fn(test_data, is_eval=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single prediction\n",
    "for imgs, _ in input_fn(test_data, is_eval=True).take(1):\n",
    "    img_idx = 50\n",
    "    plt.imshow(imgs[\"x\"][img_idx] / 255)\n",
    "    print(p[img_idx]['predicted_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.ckpt restore and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess :\n",
    "\n",
    "    # Saver instance 를 생성한다.\n",
    "    # Saver.restore(sess, ckpt_path)\n",
    "\n",
    "    saver = tf.train.import_meta_graph('/tmp/tmpv28t5kpm/model.ckpt-5563.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('/tmp/tmpv28t5kpm/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
