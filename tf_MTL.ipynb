{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training/test files in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd() + '/data/training_csv'))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd() + '/data/test_csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we are enabling eager execution for debugging!\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for handling datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load filenames and labels\n",
    "filenames = tf.constant(train_data.iloc[:, 0].tolist())\n",
    "labels = tf.constant(train_data.iloc[:, 1:].values)\n",
    "\n",
    "# Add to a dataset object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "# We can debug using eager execution\n",
    "for img, labels in dataset.batch(4).take(1):\n",
    "    print(img)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse function from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    print(filename)\n",
    "    image_string = tf.read_file(filename) \n",
    "    print(image_string)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3) \n",
    "    image_resized = tf.image.resize_images(image_decoded, [160, 160])\n",
    "    image_shape = tf.cast(tf.shape(image_decoded), tf.float32)\n",
    "    label = tf.concat([label[:]], axis=0)\n",
    "    return {\"x\": image_resized}, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet is adapted from here: https://www.tensorflow.org/guide/datasets\n",
    "def input_fn(dataframe, is_eval=False):\n",
    "\n",
    "    # Load the list of files\n",
    "    filenames = tf.constant(dataframe.iloc[:, 0].tolist())\n",
    "\n",
    "    # Load the labels\n",
    "    labels = tf.constant(dataframe.iloc[:, 1:].values)\n",
    "\n",
    "    # Build the dataset with image processing on top of it\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    # Add shuffling and repeatition if training\n",
    "    if is_eval:\n",
    "        dataset = dataset.batch(64)\n",
    "    else:\n",
    "        dataset = dataset.repeat().shuffle(1000).batch(64)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the image & some labels\n",
    "import matplotlib.pyplot as plt\n",
    "for (imgs, labels) in input_fn(train_data, is_eval=True).take(1):\n",
    "    plt.imshow(imgs['x'][0] / 255)\n",
    "    print(labels[0])\n",
    "    print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(features):\n",
    "    # Input layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 160, 160, 3])\n",
    "\n",
    "    # First convolutive layer\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=16, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Second convolutive layer\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=48, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Third convolutive layer\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fourth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fifth convolutive layer\n",
    "    conv5 = tf.layers.conv2d(inputs=pool4, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Sixth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=128, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer (Fully Connected Layer)\n",
    "    flat = tf.reshape(conv4, [-1, 20 * 20 * 128])\n",
    "    dense = tf.layers.dense(inputs=flat, units=100, activation=tf.nn.relu)\n",
    "  \n",
    "    return dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input_fn & main estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to disable the eager execution at this point\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_input_fn(data, is_eval=False):\n",
    "    features, labels = input_fn(data, is_eval=is_eval).make_one_shot_iterator().get_next()\n",
    "    return features, {'shape': labels[:, 0], 'cover': labels[:, 1], 'charm': labels[:, 2], 'pattern': labels[:, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_cnn_model_fn(features, labels, mode):\n",
    "\n",
    "    dense = extract_features(features)\n",
    "\n",
    "    # Predictions for each task\n",
    "    logits_shape = tf.layers.dense(inputs=dense, units=11)\n",
    "    logits_cover = tf.layers.dense(inputs=dense, units=3)\n",
    "    logits_charm = tf.layers.dense(inputs=dense, units=6)\n",
    "    logits_pattern = tf.layers.dense(inputs=dense, units=12)\n",
    "    \n",
    "    # Make predictions\n",
    "    \n",
    "    predicted_shape_class = tf.argmax(logits_shape, 1)\n",
    "    predicted_cover_class = tf.argmax(logits_cover, 1)\n",
    "    predicted_charm_class = tf.argmax(logits_charm, 1)\n",
    "    predicted_pattern_class = tf.argmax(logits_pattern, 1)\n",
    "    \n",
    "    logits = {'shape': logits_shape, 'cover': logits_cover, \n",
    "              'charm': logits_charm, 'pattern': logits_pattern}\n",
    "    \n",
    "    outputs = {\n",
    "        \"predicted_shape_class\": predicted_shape_class,\n",
    "        \"predicted_cover_class\": predicted_cover_class,\n",
    "        \"predicted_charm_class\": predicted_charm_class,\n",
    "        \"predicted_pattern_class\": predicted_pattern_class,\n",
    "        \"logits\": logits\n",
    "    }\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    # We just want the predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=outputs)\n",
    "\n",
    "    # If not in mode.PREDICT, compute the loss \n",
    "    shape_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['shape'], logits=logits_shape)\n",
    "    cover_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['cover'], logits=logits_cover)\n",
    "    charm_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['charm'], logits=logits_charm)\n",
    "    pattern_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['pattern'], logits=logits_pattern)\n",
    "    total_loss = shape_loss + cover_loss + charm_loss + pattern_loss\n",
    "\n",
    "    # TRAIN MODE \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss=total_loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, train_op=train_op)\n",
    "\n",
    "    # If not PREDICT or TRAIN, then we are evaluating the model\n",
    "    eval_metric_ops = {\n",
    "        \"shape_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['shape'], predictions=outputs[\"predicted_shape_class\"]), \n",
    "        \"cover_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['cover'], predictions=outputs[\"predicted_cover_class\"]), \n",
    "        \"charm_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['charm'], predictions=outputs[\"predicted_charm_class\"]), \n",
    "        \"pattern_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['pattern'], predictions=outputs[\"predicted_pattern_class\"]), \n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=total_loss, eval_metric_ops=eval_metric_ops)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimator 선언 및 training / evaluation / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_classifier = tf.estimator.Estimator(model_fn=multi_head_cnn_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_classifier.train(input_fn=lambda: multihead_input_fn(train_data), steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_classifier.evaluate(input_fn=lambda: multihead_input_fn(test_data, is_eval=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(multitask_classifier.predict(lambda: input_fn(test_data, is_eval=True)))\n",
    "print(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess :\n",
    "\n",
    "    # Saver instance 를 생성한다.\n",
    "    # Saver.restore(sess, ckpt_path)\n",
    "\n",
    "    saver = tf.train.import_meta_graph('/tmp/tmpv28t5kpm/model.ckpt-5563.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('/tmp/tmpv28t5kpm/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
