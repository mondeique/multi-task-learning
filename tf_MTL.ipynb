{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training/test files in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Desktop/multi-task-learning\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(os.getcwd() + '/data/20191120_training_csv'))\n",
    "test_data = pd.read_csv(os.path.join(os.getcwd() + '/data/20191120_test_csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Note: we are enabling eager execution for debugging!\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'./data/cropped-bag-images-dev/GQY2HJFKZ2J_1.jpg'\n",
      " b'./data/cropped-bag-images-dev/GCHQY0O9SOH_1.jpg'\n",
      " b'./data/cropped-bag-images-dev/aug_data/trapezoid/aug_K4NEBQ7AORX_1.jpg_85.jpg'\n",
      " b'./data/cropped-bag-images-dev/52J5JS9VIBK_1.jpg'], shape=(4,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 5  1  5 11]\n",
      " [ 7  2  6 11]\n",
      " [ 3  2  6 11]\n",
      " [ 2  1  6 11]], shape=(4, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Example code for handling datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load filenames and labels\n",
    "filenames = tf.constant(train_data.iloc[:, 0].tolist())\n",
    "labels = tf.constant(train_data.iloc[:, 1:].values)\n",
    "\n",
    "# Add to a dataset object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "# We can debug using eager execution\n",
    "for img, labels in dataset.batch(4).take(1):\n",
    "    print(img)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse function from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads an image from a file, decodes it into a dense tensor, and resizes it\n",
    "# to a fixed shape.\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    print(filename)\n",
    "    image_string = tf.read_file(filename) \n",
    "    print(image_string)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3) \n",
    "    image_resized = tf.image.resize_images(image_decoded, [160, 160])\n",
    "    image_shape = tf.cast(tf.shape(image_decoded), tf.float32)\n",
    "    label = tf.concat([label[:]], axis=0)\n",
    "    return {\"x\": image_resized}, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet is adapted from here: https://www.tensorflow.org/guide/datasets\n",
    "def input_fn(dataframe, is_eval=False):\n",
    "\n",
    "    # Load the list of files\n",
    "    filenames = tf.constant(dataframe.iloc[:, 0].tolist())\n",
    "\n",
    "    # Load the labels\n",
    "    labels = tf.constant(dataframe.iloc[:, 1:].values)\n",
    "\n",
    "    # Build the dataset with image processing on top of it\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    # Add shuffling and repeatition if training\n",
    "    if is_eval:\n",
    "        dataset = dataset.batch(64)\n",
    "    else:\n",
    "        dataset = dataset.repeat().shuffle(1000).batch(64)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
      "tf.Tensor([ 5  1  5 11], shape=(4,), dtype=int64)\n",
      "tf.Tensor([ 7  2  6 11], shape=(4,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the image & some labels\n",
    "import matplotlib.pyplot as plt\n",
    "for (imgs, labels) in input_fn(train_data, is_eval=True).take(1):\n",
    "    plt.imshow(imgs['x'][0] / 255)\n",
    "    print(labels[0])\n",
    "    print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(features):\n",
    "    # Input layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 160, 160, 3])\n",
    "\n",
    "    # First convolutive layer\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=16, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Second convolutive layer\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=48, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Third convolutive layer\n",
    "    conv3 = tf.layers.conv2d(inputs=pool2, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fourth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Fifth convolutive layer\n",
    "    conv5 = tf.layers.conv2d(inputs=pool4, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Sixth convolutive layer\n",
    "    conv4 = tf.layers.conv2d(inputs=pool3, filters=128, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer (Fully Connected Layer)\n",
    "    flat = tf.reshape(conv4, [-1, 20 * 20 * 128])\n",
    "    dense = tf.layers.dense(inputs=flat, units=100, activation=tf.nn.relu)\n",
    "  \n",
    "    return dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input_fn & main estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to disable the eager execution at this point\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def multi_input_fn(data, is_eval=False):\n",
    "    features, labels = input_fn(data, is_eval=is_eval).make_one_shot_iterator().get_next()\n",
    "    return features, {'shape': labels[:, 0], 'cover': labels[:, 1], 'charm': labels[:, 2], 'pattern': labels[:, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cnn_model_fn(features, labels, mode):\n",
    "\n",
    "    dense = extract_features(features)\n",
    "\n",
    "    # Predictions for each task\n",
    "    logits_shape = tf.layers.dense(inputs=dense, units=11)\n",
    "    logits_cover = tf.layers.dense(inputs=dense, units=3)\n",
    "    logits_charm = tf.layers.dense(inputs=dense, units=7)\n",
    "    logits_pattern = tf.layers.dense(inputs=dense, units=12)\n",
    "    \n",
    "    # Make predictions\n",
    "    \n",
    "    predicted_shape_class = tf.argmax(logits_shape, 1)\n",
    "    predicted_cover_class = tf.argmax(logits_cover, 1)\n",
    "    predicted_charm_class = tf.argmax(logits_charm, 1)\n",
    "    predicted_pattern_class = tf.argmax(logits_pattern, 1)\n",
    "    \n",
    "    logits = {'shape': logits_shape, 'cover': logits_cover, \n",
    "              'charm': logits_charm, 'pattern': logits_pattern}\n",
    "    \n",
    "    outputs = {\n",
    "        \"predicted_shape_class\": predicted_shape_class,\n",
    "        \"predicted_cover_class\": predicted_cover_class,\n",
    "        \"predicted_charm_class\": predicted_charm_class,\n",
    "        \"predicted_pattern_class\": predicted_pattern_class\n",
    "    }\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    # We just want the predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=outputs)\n",
    "\n",
    "    # If not in mode.PREDICT, compute the loss \n",
    "    shape_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['shape'], logits=logits_shape)\n",
    "    cover_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['cover'], logits=logits_cover)\n",
    "    charm_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['charm'], logits=logits_charm)\n",
    "    pattern_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels['pattern'], logits=logits_pattern)\n",
    "    total_loss = shape_loss + cover_loss + charm_loss + pattern_loss\n",
    "\n",
    "    # TRAIN MODE \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss=total_loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, train_op=train_op)\n",
    "\n",
    "    # If not PREDICT or TRAIN, then we are evaluating the model\n",
    "    eval_metric_ops = {\n",
    "        \"shape_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['shape'], predictions=outputs[\"predicted_shape_class\"]), \n",
    "        \"cover_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['cover'], predictions=outputs[\"predicted_cover_class\"]), \n",
    "        \"charm_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['charm'], predictions=outputs[\"predicted_charm_class\"]), \n",
    "        \"pattern_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels['pattern'], predictions=outputs[\"predicted_pattern_class\"]), \n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=total_loss, eval_metric_ops=eval_metric_ops)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimator 선언 및 training / evaluation / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpoves15jc\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpoves15jc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3e903fb150>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "multitask_classifier = tf.estimator.Estimator(model_fn=multi_cnn_model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
      "WARNING:tensorflow:From <ipython-input-9-d179b3e5faeb>:6: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-8-be25a1dba81b>:6: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-8-be25a1dba81b>:7: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e9bd4f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-8-be25a1dba81b>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3ee7597050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:loss = 68.25652, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.12663\n",
      "INFO:tensorflow:loss = 2.9209337, step = 101 (88.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13855\n",
      "INFO:tensorflow:loss = 1.0854232, step = 201 (87.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14001\n",
      "INFO:tensorflow:loss = 0.24387504, step = 301 (87.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1403\n",
      "INFO:tensorflow:loss = 0.07371551, step = 401 (87.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13774\n",
      "INFO:tensorflow:loss = 0.100628726, step = 501 (87.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14005\n",
      "INFO:tensorflow:loss = 0.0746838, step = 601 (87.716 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 680 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14126\n",
      "INFO:tensorflow:loss = 0.058265705, step = 701 (87.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14772\n",
      "INFO:tensorflow:loss = 0.0009003996, step = 801 (87.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14493\n",
      "INFO:tensorflow:loss = 0.00072466175, step = 901 (87.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14518\n",
      "INFO:tensorflow:loss = 0.0005350129, step = 1001 (87.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14284\n",
      "INFO:tensorflow:loss = 0.00043576956, step = 1101 (87.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14337\n",
      "INFO:tensorflow:loss = 0.0003171091, step = 1201 (87.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14551\n",
      "INFO:tensorflow:loss = 0.00030284468, step = 1301 (87.297 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1367 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14306\n",
      "INFO:tensorflow:loss = 0.00025971254, step = 1401 (87.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14206\n",
      "INFO:tensorflow:loss = 0.00017179947, step = 1501 (87.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14309\n",
      "INFO:tensorflow:loss = 9.297108e-05, step = 1601 (87.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14183\n",
      "INFO:tensorflow:loss = 9.643679e-05, step = 1701 (87.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14196\n",
      "INFO:tensorflow:loss = 0.00015839441, step = 1801 (87.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14298\n",
      "INFO:tensorflow:loss = 4.8760194e-05, step = 1901 (87.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1401\n",
      "INFO:tensorflow:loss = 0.00010597413, step = 2001 (87.711 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2053 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14248\n",
      "INFO:tensorflow:loss = 9.303457e-05, step = 2101 (87.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14467\n",
      "INFO:tensorflow:loss = 0.00011354319, step = 2201 (87.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14316\n",
      "INFO:tensorflow:loss = 3.888822e-05, step = 2301 (87.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14529\n",
      "INFO:tensorflow:loss = 5.7049696e-05, step = 2401 (87.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14478\n",
      "INFO:tensorflow:loss = 5.789436e-05, step = 2501 (87.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13464\n",
      "INFO:tensorflow:loss = 3.789871e-05, step = 2601 (88.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13851\n",
      "INFO:tensorflow:loss = 6.0856924e-05, step = 2701 (87.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2738 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13652\n",
      "INFO:tensorflow:loss = 3.6025554e-05, step = 2801 (87.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14186\n",
      "INFO:tensorflow:loss = 5.255042e-05, step = 2901 (87.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14774\n",
      "INFO:tensorflow:loss = 2.355049e-05, step = 3001 (87.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14688\n",
      "INFO:tensorflow:loss = 8.026953e-05, step = 3101 (87.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14563\n",
      "INFO:tensorflow:loss = 2.7878377e-05, step = 3201 (87.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14706\n",
      "INFO:tensorflow:loss = 2.4096273e-05, step = 3301 (87.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1441\n",
      "INFO:tensorflow:loss = 3.938766e-05, step = 3401 (87.405 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3425 into /tmp/tmpoves15jc/model.ckpt.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 1.13862\n",
      "INFO:tensorflow:loss = 3.0065745e-05, step = 3501 (87.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14323\n",
      "INFO:tensorflow:loss = 1.3876501e-05, step = 3601 (87.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1469\n",
      "INFO:tensorflow:loss = 1.6087333e-05, step = 3701 (87.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14411\n",
      "INFO:tensorflow:loss = 2.2254371e-05, step = 3801 (87.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14342\n",
      "INFO:tensorflow:loss = 3.0786057e-05, step = 3901 (87.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14397\n",
      "INFO:tensorflow:loss = 1.9827174e-05, step = 4001 (87.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14547\n",
      "INFO:tensorflow:loss = 1.7443159e-05, step = 4101 (87.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4112 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14389\n",
      "INFO:tensorflow:loss = 2.7770304e-05, step = 4201 (87.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14275\n",
      "INFO:tensorflow:loss = 1.5500522e-05, step = 4301 (87.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14222\n",
      "INFO:tensorflow:loss = 1.6346035e-05, step = 4401 (87.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14416\n",
      "INFO:tensorflow:loss = 9.613006e-06, step = 4501 (87.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14483\n",
      "INFO:tensorflow:loss = 9.506824e-06, step = 4601 (87.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14005\n",
      "INFO:tensorflow:loss = 9.935152e-06, step = 4701 (87.716 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4798 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14234\n",
      "INFO:tensorflow:loss = 8.01861e-06, step = 4801 (87.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14237\n",
      "INFO:tensorflow:loss = 8.404136e-06, step = 4901 (87.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14272\n",
      "INFO:tensorflow:loss = 8.763575e-06, step = 5001 (87.510 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.14121\n",
      "INFO:tensorflow:loss = 1.0441862e-05, step = 5101 (87.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14499\n",
      "INFO:tensorflow:loss = 7.742922e-06, step = 5201 (87.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14391\n",
      "INFO:tensorflow:loss = 6.0572784e-06, step = 5301 (87.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1422\n",
      "INFO:tensorflow:loss = 3.85938e-06, step = 5401 (87.550 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5484 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14022\n",
      "INFO:tensorflow:loss = 4.3753244e-06, step = 5501 (87.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14196\n",
      "INFO:tensorflow:loss = 1.2771836e-05, step = 5601 (87.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13829\n",
      "INFO:tensorflow:loss = 4.988119e-06, step = 5701 (87.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14219\n",
      "INFO:tensorflow:loss = 5.561806e-06, step = 5801 (87.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14443\n",
      "INFO:tensorflow:loss = 7.346176e-06, step = 5901 (87.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14444\n",
      "INFO:tensorflow:loss = 4.967633e-06, step = 6001 (87.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14319\n",
      "INFO:tensorflow:loss = 4.151808e-06, step = 6101 (87.474 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6170 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14069\n",
      "INFO:tensorflow:loss = 3.9450438e-06, step = 6201 (87.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1436\n",
      "INFO:tensorflow:loss = 3.386277e-06, step = 6301 (87.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14462\n",
      "INFO:tensorflow:loss = 6.418587e-06, step = 6401 (87.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14439\n",
      "INFO:tensorflow:loss = 4.006518e-06, step = 6501 (87.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14265\n",
      "INFO:tensorflow:loss = 2.469858e-06, step = 6601 (87.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1391\n",
      "INFO:tensorflow:loss = 3.810946e-06, step = 6701 (87.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14212\n",
      "INFO:tensorflow:loss = 2.6728858e-06, step = 6801 (87.557 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6856 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13871\n",
      "INFO:tensorflow:loss = 3.2316734e-06, step = 6901 (87.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14509\n",
      "INFO:tensorflow:loss = 1.0039647e-06, step = 7001 (87.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14193\n",
      "INFO:tensorflow:loss = 2.1047776e-06, step = 7101 (87.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14563\n",
      "INFO:tensorflow:loss = 3.6991976e-06, step = 7201 (87.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14361\n",
      "INFO:tensorflow:loss = 1.8775416e-06, step = 7301 (87.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14264\n",
      "INFO:tensorflow:loss = 2.5052495e-06, step = 7401 (87.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14396\n",
      "INFO:tensorflow:loss = 3.5874275e-06, step = 7501 (87.415 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7542 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14307\n",
      "INFO:tensorflow:loss = 1.5906954e-06, step = 7601 (87.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.142\n",
      "INFO:tensorflow:loss = 1.3988431e-06, step = 7701 (87.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14402\n",
      "INFO:tensorflow:loss = 1.9036183e-06, step = 7801 (87.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14389\n",
      "INFO:tensorflow:loss = 1.2535573e-06, step = 7901 (87.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14524\n",
      "INFO:tensorflow:loss = 1.5236388e-06, step = 8001 (87.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14221\n",
      "INFO:tensorflow:loss = 1.2293444e-06, step = 8101 (87.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14029\n",
      "INFO:tensorflow:loss = 2.175559e-06, step = 8201 (87.698 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8228 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14143\n",
      "INFO:tensorflow:loss = 7.245685e-07, step = 8301 (87.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13986\n",
      "INFO:tensorflow:loss = 1.1641513e-06, step = 8401 (87.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14238\n",
      "INFO:tensorflow:loss = 8.9965664e-07, step = 8501 (87.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13983\n",
      "INFO:tensorflow:loss = 1.1753269e-06, step = 8601 (87.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14099\n",
      "INFO:tensorflow:loss = 6.128098e-07, step = 8701 (87.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14026\n",
      "INFO:tensorflow:loss = 9.2573316e-07, step = 8801 (87.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14156\n",
      "INFO:tensorflow:loss = 8.7730507e-07, step = 8901 (87.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8913 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13793\n",
      "INFO:tensorflow:loss = 1.0803324e-06, step = 9001 (87.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14221\n",
      "INFO:tensorflow:loss = 8.6240334e-07, step = 9101 (87.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14071\n",
      "INFO:tensorflow:loss = 7.133925e-07, step = 9201 (87.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14602\n",
      "INFO:tensorflow:loss = 9.555342e-07, step = 9301 (87.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14385\n",
      "INFO:tensorflow:loss = 1.1213103e-06, step = 9401 (87.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1442\n",
      "INFO:tensorflow:loss = 6.128099e-07, step = 9501 (87.397 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9599 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14005\n",
      "INFO:tensorflow:loss = 7.4692014e-07, step = 9601 (87.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14269\n",
      "INFO:tensorflow:loss = 5.6438097e-07, step = 9701 (87.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14407\n",
      "INFO:tensorflow:loss = 5.811449e-07, step = 9801 (87.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13982\n",
      "INFO:tensorflow:loss = 7.8230977e-07, step = 9901 (87.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14174\n",
      "INFO:tensorflow:loss = 8.717166e-07, step = 10001 (87.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14307\n",
      "INFO:tensorflow:loss = 4.4703455e-07, step = 10101 (87.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1385\n",
      "INFO:tensorflow:loss = 3.35276e-07, step = 10201 (87.835 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10284 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13831\n",
      "INFO:tensorflow:loss = 5.0477644e-07, step = 10301 (87.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1443\n",
      "INFO:tensorflow:loss = 3.9488063e-07, step = 10401 (87.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14424\n",
      "INFO:tensorflow:loss = 8.195629e-07, step = 10501 (87.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14773\n",
      "INFO:tensorflow:loss = 2.4586902e-07, step = 10601 (87.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14184\n",
      "INFO:tensorflow:loss = 3.576277e-07, step = 10701 (87.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13984\n",
      "INFO:tensorflow:loss = 2.5331963e-07, step = 10801 (87.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13938\n",
      "INFO:tensorflow:loss = 2.7194608e-07, step = 10901 (87.767 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10970 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.1392\n",
      "INFO:tensorflow:loss = 3.1478694e-07, step = 11001 (87.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13995\n",
      "INFO:tensorflow:loss = 2.4959434e-07, step = 11101 (87.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14042\n",
      "INFO:tensorflow:loss = 3.7066616e-07, step = 11201 (87.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14096\n",
      "INFO:tensorflow:loss = 3.2223744e-07, step = 11301 (87.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14152\n",
      "INFO:tensorflow:loss = 1.7695123e-07, step = 11401 (87.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14215\n",
      "INFO:tensorflow:loss = 2.3283057e-07, step = 11501 (87.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14373\n",
      "INFO:tensorflow:loss = 1.881271e-07, step = 11601 (87.433 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11655 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14132\n",
      "INFO:tensorflow:loss = 1.8067654e-07, step = 11701 (87.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14298\n",
      "INFO:tensorflow:loss = 9.126959e-08, step = 11801 (87.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14244\n",
      "INFO:tensorflow:loss = 1.7881385e-07, step = 11901 (87.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1404\n",
      "INFO:tensorflow:loss = 1.0617076e-07, step = 12001 (87.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14032\n",
      "INFO:tensorflow:loss = 1.00582824e-07, step = 12101 (87.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1920926e-07, step = 12201 (87.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14354\n",
      "INFO:tensorflow:loss = 1.15483985e-07, step = 12301 (87.448 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12340 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14187\n",
      "INFO:tensorflow:loss = 8.940695e-08, step = 12401 (87.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13963\n",
      "INFO:tensorflow:loss = 6.519257e-08, step = 12501 (87.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13917\n",
      "INFO:tensorflow:loss = 6.332993e-08, step = 12601 (87.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14059\n",
      "INFO:tensorflow:loss = 1.080334e-07, step = 12701 (87.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13984\n",
      "INFO:tensorflow:loss = 8.754431e-08, step = 12801 (87.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14002\n",
      "INFO:tensorflow:loss = 1.247972e-07, step = 12901 (87.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09716\n",
      "INFO:tensorflow:loss = 1.210719e-07, step = 13001 (91.145 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13020 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11005\n",
      "INFO:tensorflow:loss = 7.2643154e-08, step = 13101 (90.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10369\n",
      "INFO:tensorflow:loss = 1.0617076e-07, step = 13201 (90.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10436\n",
      "INFO:tensorflow:loss = 7.450579e-08, step = 13301 (90.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10418\n",
      "INFO:tensorflow:loss = 1.00582824e-07, step = 13401 (90.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1033\n",
      "INFO:tensorflow:loss = 5.7741993e-08, step = 13501 (90.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11504\n",
      "INFO:tensorflow:loss = 9.685753e-08, step = 13601 (89.683 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13685 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11335\n",
      "INFO:tensorflow:loss = 7.636844e-08, step = 13701 (89.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11635\n",
      "INFO:tensorflow:loss = 6.5192566e-08, step = 13801 (89.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11502\n",
      "INFO:tensorflow:loss = 1.5273687e-07, step = 13901 (89.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11372\n",
      "INFO:tensorflow:loss = 8.754431e-08, step = 14001 (89.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10994\n",
      "INFO:tensorflow:loss = 7.6368444e-08, step = 14101 (90.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11489\n",
      "INFO:tensorflow:loss = 5.029141e-08, step = 14201 (89.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1013\n",
      "INFO:tensorflow:loss = 5.7741993e-08, step = 14301 (90.801 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14353 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11566\n",
      "INFO:tensorflow:loss = 5.215406e-08, step = 14401 (89.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09671\n",
      "INFO:tensorflow:loss = 5.0291412e-08, step = 14501 (91.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11522\n",
      "INFO:tensorflow:loss = 3.5390254e-08, step = 14601 (89.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10986\n",
      "INFO:tensorflow:loss = 3.9115545e-08, step = 14701 (90.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11713\n",
      "INFO:tensorflow:loss = 7.07805e-08, step = 14801 (89.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10501\n",
      "INFO:tensorflow:loss = 4.8428767e-08, step = 14901 (90.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.09621\n",
      "INFO:tensorflow:loss = 4.097819e-08, step = 15001 (91.223 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15018 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.10464\n",
      "INFO:tensorflow:loss = 4.4703476e-08, step = 15101 (90.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12659\n",
      "INFO:tensorflow:loss = 5.0291415e-08, step = 15201 (88.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10604\n",
      "INFO:tensorflow:loss = 4.2840835e-08, step = 15301 (90.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10769\n",
      "INFO:tensorflow:loss = 7.450579e-08, step = 15401 (90.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11616\n",
      "INFO:tensorflow:loss = 3.352761e-08, step = 15501 (89.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11701\n",
      "INFO:tensorflow:loss = 8.568166e-08, step = 15601 (89.525 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15687 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11813\n",
      "INFO:tensorflow:loss = 5.7741985e-08, step = 15701 (89.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11979\n",
      "INFO:tensorflow:loss = 4.0978186e-08, step = 15801 (89.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12439\n",
      "INFO:tensorflow:loss = 2.4214385e-08, step = 15901 (88.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11386\n",
      "INFO:tensorflow:loss = 4.4703476e-08, step = 16001 (89.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11861\n",
      "INFO:tensorflow:loss = 4.097819e-08, step = 16101 (89.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11916\n",
      "INFO:tensorflow:loss = 5.0291412e-08, step = 16201 (89.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11689\n",
      "INFO:tensorflow:loss = 3.72529e-08, step = 16301 (89.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16358 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11214\n",
      "INFO:tensorflow:loss = 1.862645e-08, step = 16401 (89.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11258\n",
      "INFO:tensorflow:loss = 4.4703476e-08, step = 16501 (89.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1181\n",
      "INFO:tensorflow:loss = 2.6077029e-08, step = 16601 (89.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1184\n",
      "INFO:tensorflow:loss = 3.1664964e-08, step = 16701 (89.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11814\n",
      "INFO:tensorflow:loss = 2.0489095e-08, step = 16801 (89.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11511\n",
      "INFO:tensorflow:loss = 1.862645e-08, step = 16901 (89.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11912\n",
      "INFO:tensorflow:loss = 3.1664964e-08, step = 17001 (89.356 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17028 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12453\n",
      "INFO:tensorflow:loss = 3.352761e-08, step = 17101 (88.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13571\n",
      "INFO:tensorflow:loss = 3.72529e-08, step = 17201 (88.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13352\n",
      "INFO:tensorflow:loss = 2.4214385e-08, step = 17301 (88.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1335\n",
      "INFO:tensorflow:loss = 1.6763805e-08, step = 17401 (88.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13276\n",
      "INFO:tensorflow:loss = 5.0291412e-08, step = 17501 (88.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13284\n",
      "INFO:tensorflow:loss = 3.5390254e-08, step = 17601 (88.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12855\n",
      "INFO:tensorflow:loss = 7.823108e-08, step = 17701 (88.609 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17708 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.12137\n",
      "INFO:tensorflow:loss = 1.490116e-08, step = 17801 (89.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13002\n",
      "INFO:tensorflow:loss = 1.3038515e-08, step = 17901 (88.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13347\n",
      "INFO:tensorflow:loss = 9.12696e-08, step = 18001 (88.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.12246\n",
      "INFO:tensorflow:loss = 4.097819e-08, step = 18101 (89.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.10535\n",
      "INFO:tensorflow:loss = 3.72529e-08, step = 18201 (90.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11741\n",
      "INFO:tensorflow:loss = 4.4703476e-08, step = 18301 (89.493 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18381 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.11211\n",
      "INFO:tensorflow:loss = 2.4214385e-08, step = 18401 (89.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11804\n",
      "INFO:tensorflow:loss = 2.235174e-08, step = 18501 (89.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1136\n",
      "INFO:tensorflow:loss = 2.607703e-08, step = 18601 (89.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11518\n",
      "INFO:tensorflow:loss = 2.7939675e-08, step = 18701 (89.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13688\n",
      "INFO:tensorflow:loss = 9.313225e-09, step = 18801 (87.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13698\n",
      "INFO:tensorflow:loss = 5.215406e-08, step = 18901 (87.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13759\n",
      "INFO:tensorflow:loss = 2.235174e-08, step = 19001 (87.905 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19057 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13507\n",
      "INFO:tensorflow:loss = 1.6763805e-08, step = 19101 (88.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13702\n",
      "INFO:tensorflow:loss = 2.6077029e-08, step = 19201 (87.949 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.13503\n",
      "INFO:tensorflow:loss = 1.862645e-08, step = 19301 (88.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13586\n",
      "INFO:tensorflow:loss = 7.45058e-09, step = 19401 (88.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13839\n",
      "INFO:tensorflow:loss = 1.117587e-08, step = 19501 (87.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1382\n",
      "INFO:tensorflow:loss = 0.0, step = 19601 (87.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13464\n",
      "INFO:tensorflow:loss = 1.6763805e-08, step = 19701 (88.133 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19739 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.13519\n",
      "INFO:tensorflow:loss = 1.490116e-08, step = 19801 (88.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.13773\n",
      "INFO:tensorflow:loss = 1.30385e-07, step = 19901 (87.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14\n",
      "INFO:tensorflow:loss = 1.1272311, step = 20001 (87.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14501\n",
      "INFO:tensorflow:loss = 0.1614504, step = 20101 (87.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14627\n",
      "INFO:tensorflow:loss = 0.0031338935, step = 20201 (87.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14633\n",
      "INFO:tensorflow:loss = 0.00054862164, step = 20301 (87.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14759\n",
      "INFO:tensorflow:loss = 0.00017912893, step = 20401 (87.139 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20425 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14477\n",
      "INFO:tensorflow:loss = 0.000107766355, step = 20501 (87.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15074\n",
      "INFO:tensorflow:loss = 2.7774262e-05, step = 20601 (86.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14745\n",
      "INFO:tensorflow:loss = 1.338255e-05, step = 20701 (87.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14655\n",
      "INFO:tensorflow:loss = 9.223648e-06, step = 20801 (87.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14617\n",
      "INFO:tensorflow:loss = 4.911757e-06, step = 20901 (87.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14717\n",
      "INFO:tensorflow:loss = 1.8496025e-06, step = 21001 (87.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14931\n",
      "INFO:tensorflow:loss = 1.6520198e-05, step = 21101 (87.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21114 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.1456\n",
      "INFO:tensorflow:loss = 1.844015e-06, step = 21201 (87.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15083\n",
      "INFO:tensorflow:loss = 1.4323712e-06, step = 21301 (86.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14707\n",
      "INFO:tensorflow:loss = 1.6577507e-06, step = 21401 (87.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14955\n",
      "INFO:tensorflow:loss = 8.512282e-07, step = 21501 (86.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14919\n",
      "INFO:tensorflow:loss = 7.189806e-07, step = 21601 (87.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14677\n",
      "INFO:tensorflow:loss = 1.002102e-06, step = 21701 (87.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14921\n",
      "INFO:tensorflow:loss = 6.239857e-07, step = 21801 (87.016 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21804 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.1495\n",
      "INFO:tensorflow:loss = 5.0477655e-07, step = 21901 (86.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15097\n",
      "INFO:tensorflow:loss = 5.550677e-07, step = 22001 (86.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14896\n",
      "INFO:tensorflow:loss = 2.626329e-07, step = 22101 (87.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14979\n",
      "INFO:tensorflow:loss = 2.2779823e-06, step = 22201 (86.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14918\n",
      "INFO:tensorflow:loss = 3.2968808e-07, step = 22301 (87.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14882\n",
      "INFO:tensorflow:loss = 1.9185242e-07, step = 22401 (87.045 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22494 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14674\n",
      "INFO:tensorflow:loss = 3.4458918e-07, step = 22501 (87.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14433\n",
      "INFO:tensorflow:loss = 2.7753404e-07, step = 22601 (87.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15003\n",
      "INFO:tensorflow:loss = 1.210719e-07, step = 22701 (86.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14656\n",
      "INFO:tensorflow:loss = 1.5273687e-07, step = 22801 (87.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14798\n",
      "INFO:tensorflow:loss = 1.4342365e-07, step = 22901 (87.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14625\n",
      "INFO:tensorflow:loss = 3.2410003e-07, step = 23001 (87.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14861\n",
      "INFO:tensorflow:loss = 1.00582824e-07, step = 23101 (87.062 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23183 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.1446\n",
      "INFO:tensorflow:loss = 1.3411042e-07, step = 23201 (87.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14798\n",
      "INFO:tensorflow:loss = 8.3819025e-08, step = 23301 (87.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14923\n",
      "INFO:tensorflow:loss = 1.1920926e-07, step = 23401 (87.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14668\n",
      "INFO:tensorflow:loss = 8.381902e-08, step = 23501 (87.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14636\n",
      "INFO:tensorflow:loss = 7.45058e-08, step = 23601 (87.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14839\n",
      "INFO:tensorflow:loss = 5.569293e-07, step = 23701 (87.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1505\n",
      "INFO:tensorflow:loss = 5.0291412e-08, step = 23801 (86.919 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23872 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14453\n",
      "INFO:tensorflow:loss = 4.656612e-08, step = 23901 (87.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14812\n",
      "INFO:tensorflow:loss = 1.0989604e-07, step = 24001 (87.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1481\n",
      "INFO:tensorflow:loss = 3.72529e-08, step = 24101 (87.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14679\n",
      "INFO:tensorflow:loss = 4.470348e-08, step = 24201 (87.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14706\n",
      "INFO:tensorflow:loss = 4.842877e-08, step = 24301 (87.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1481\n",
      "INFO:tensorflow:loss = 3.352761e-08, step = 24401 (87.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14485\n",
      "INFO:tensorflow:loss = 2.0489095e-08, step = 24501 (87.348 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24561 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14688\n",
      "INFO:tensorflow:loss = 6.332992e-08, step = 24601 (87.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14667\n",
      "INFO:tensorflow:loss = 3.352761e-08, step = 24701 (87.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1491\n",
      "INFO:tensorflow:loss = 5.5879347e-08, step = 24801 (87.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14759\n",
      "INFO:tensorflow:loss = 3.352761e-08, step = 24901 (87.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14852\n",
      "INFO:tensorflow:loss = 1.6763805e-08, step = 25001 (87.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14887\n",
      "INFO:tensorflow:loss = 2.7939674e-08, step = 25101 (87.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14613\n",
      "INFO:tensorflow:loss = 1.6763805e-08, step = 25201 (87.250 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25250 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14893\n",
      "INFO:tensorflow:loss = 7.636844e-08, step = 25301 (87.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14681\n",
      "INFO:tensorflow:loss = 2.9802319e-08, step = 25401 (87.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14566\n",
      "INFO:tensorflow:loss = 2.6077029e-08, step = 25501 (87.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15196\n",
      "INFO:tensorflow:loss = 3.1664964e-08, step = 25601 (86.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15276\n",
      "INFO:tensorflow:loss = 5.15082e-05, step = 25701 (86.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14776\n",
      "INFO:tensorflow:loss = 0.014357987, step = 25801 (87.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1514\n",
      "INFO:tensorflow:loss = 0.0015580686, step = 25901 (86.851 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25940 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14873\n",
      "INFO:tensorflow:loss = 0.044594843, step = 26001 (87.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15238\n",
      "INFO:tensorflow:loss = 0.0001266871, step = 26101 (86.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15385\n",
      "INFO:tensorflow:loss = 0.00012338391, step = 26201 (86.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15424\n",
      "INFO:tensorflow:loss = 7.752194e-06, step = 26301 (86.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.9976537e-06, step = 26401 (87.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14957\n",
      "INFO:tensorflow:loss = 9.180879e-06, step = 26501 (86.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14878\n",
      "INFO:tensorflow:loss = 2.5760248e-06, step = 26601 (87.048 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26631 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14856\n",
      "INFO:tensorflow:loss = 3.2670573e-06, step = 26701 (87.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15126\n",
      "INFO:tensorflow:loss = 4.483357e-06, step = 26801 (86.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15458\n",
      "INFO:tensorflow:loss = 2.4307437e-06, step = 26901 (86.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14817\n",
      "INFO:tensorflow:loss = 1.6316731e-06, step = 27001 (87.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15165\n",
      "INFO:tensorflow:loss = 9.480849e-07, step = 27101 (86.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15172\n",
      "INFO:tensorflow:loss = 1.484522e-06, step = 27201 (86.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1497\n",
      "INFO:tensorflow:loss = 9.4436024e-07, step = 27301 (86.979 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27322 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.15026\n",
      "INFO:tensorflow:loss = 1.5627568e-06, step = 27401 (86.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14979\n",
      "INFO:tensorflow:loss = 1.0356281e-06, step = 27501 (86.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15153\n",
      "INFO:tensorflow:loss = 6.929034e-07, step = 27601 (86.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15393\n",
      "INFO:tensorflow:loss = 1.601869e-06, step = 27701 (86.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15525\n",
      "INFO:tensorflow:loss = 6.1653475e-07, step = 27801 (86.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14972\n",
      "INFO:tensorflow:loss = 9.1269254e-07, step = 27901 (86.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15358\n",
      "INFO:tensorflow:loss = 3.7439156e-07, step = 28001 (86.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28014 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14901\n",
      "INFO:tensorflow:loss = 6.537874e-07, step = 28101 (87.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15019\n",
      "INFO:tensorflow:loss = 3.0919895e-07, step = 28201 (86.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15086\n",
      "INFO:tensorflow:loss = 1.9743784e-06, step = 28301 (86.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1546\n",
      "INFO:tensorflow:loss = 1.5832276e-06, step = 28401 (86.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15091\n",
      "INFO:tensorflow:loss = 2.644955e-07, step = 28501 (86.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15126\n",
      "INFO:tensorflow:loss = 2.0489094e-07, step = 28601 (86.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15322\n",
      "INFO:tensorflow:loss = 5.401665e-07, step = 28701 (86.713 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28705 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.14865\n",
      "INFO:tensorflow:loss = 1.9929962e-06, step = 28801 (87.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15046\n",
      "INFO:tensorflow:loss = 3.8929258e-07, step = 28901 (86.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1527\n",
      "INFO:tensorflow:loss = 4.1536964e-07, step = 29001 (86.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15218\n",
      "INFO:tensorflow:loss = 9.2386676e-07, step = 29101 (86.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14609\n",
      "INFO:tensorflow:loss = 5.662437e-07, step = 29201 (87.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.1499\n",
      "INFO:tensorflow:loss = 3.241001e-07, step = 29301 (86.964 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29396 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.15086\n",
      "INFO:tensorflow:loss = 1.5646216e-07, step = 29401 (86.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15109\n",
      "INFO:tensorflow:loss = 1.9744031e-07, step = 29501 (86.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14742\n",
      "INFO:tensorflow:loss = 1.6205007e-07, step = 29601 (87.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14996\n",
      "INFO:tensorflow:loss = 1.1920925e-07, step = 29701 (86.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.14945\n",
      "INFO:tensorflow:loss = 1.2293455e-07, step = 29801 (86.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.15034\n",
      "INFO:tensorflow:loss = 2.2165473e-07, step = 29901 (86.931 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /tmp/tmpoves15jc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.6763798e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f3e903ed610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multitask_classifier.train(input_fn=lambda: multi_input_fn(train_data), steps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e400bdc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e400bdc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e400bdc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e400bdc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e400bdc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e400bdc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e400bdc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e400bdc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e38629f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e38629f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e38629f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e38629f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3e5c3eed90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e38236710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3e90075a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-22T17:13:51Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/mondeique/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpoves15jc/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-22-17:13:52\n",
      "INFO:tensorflow:Saving dict for global step 30000: charm_accuracy = 0.8729792, cover_accuracy = 0.8683603, global_step = 30000, loss = 20.509129, pattern_accuracy = 0.62355655, shape_accuracy = 0.5588915\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: /tmp/tmpoves15jc/model.ckpt-30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'charm_accuracy': 0.8729792,\n",
       " 'cover_accuracy': 0.8683603,\n",
       " 'loss': 20.509129,\n",
       " 'pattern_accuracy': 0.62355655,\n",
       " 'shape_accuracy': 0.5588915,\n",
       " 'global_step': 30000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multitask_classifier.evaluate(input_fn=lambda: multi_input_fn(test_data, is_eval=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_classifier.predict(lambda: input_fn(test_data, is_eval=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess :\n",
    "\n",
    "    # Saver instance 를 생성한다.\n",
    "    # Saver.restore(sess, ckpt_path)\n",
    "\n",
    "    saver = tf.train.import_meta_graph('/tmp/tmpv28t5kpm/model.ckpt-5563.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('/tmp/tmpv28t5kpm/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
